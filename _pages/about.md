---
permalink: /
title: "About Me"
excerpt: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My name is Zhihan Zhang (张智涵). I am an Applied Scientist at Amazon, where I work on building Rufus, Amazon’s large language model agent tailored for shopping applications. My current work focuses on improving the general instruction-following capabilities of the Rufus model, as part of its post-training efforts. 

Prior to joining industry, I earned my Ph.D. in Computer Science from the University of Notre Dame, where I was advised by [Dr. Meng Jiang](http://www.meng-jiang.com/). During my Ph.D., my research centered on training and evaluation methods for instruction-following LLMs. I received my Bachelor’s degree from Peking University, where I worked with [Dr. Yunfang Wu](https://cs.pku.edu.cn/info/1237/2096.htm) and [Dr. Xu Sun](https://xusun.org/). I gave a tutorial about instruction-following LLMs at [EMNLP 2025](https://instruction-tuning-tutorial-2025.github.io/).

For my past education and internship experience, please refer to [Experience](http://ytyz1307zzh.github.io/experience). For the full list of my publications, please refer to [Publications](http://ytyz1307zzh.github.io/publications) or check my [Google Scholar page](https://scholar.google.com/citations?user=7dcunDUAAAAJ&hl=en).

News
======
-  <img src="../images/new.png" width="25" align=center> Nov 2025: I gave a tutorial about instruction-following LLMs at [EMNLP 2025](https://instruction-tuning-tutorial-2025.github.io/). The tutorial covers training methods, evaluation benchmarks, data collection, and explanability analyses of instruction-following LLMs. Check out our [slides](https://drive.google.com/drive/folders/1RLIlKoxkk4wOsV2FylLZq0til_wH4xtC?usp=sharing) and [video](https://underline.io/events/502/sessions?searchGroup=lecture&trackIds=2497&eventSessionId=20910&eventId=502)!
 
-  May 2025: A [co-authored paper](https://arxiv.org/abs/2506.04463) was accepted by **ACL 2025**! We proposed a novel framework that leverages implicit user preferences to generate preference tuning data for LLMs.

- May 2025: A [co-authored paper](https://arxiv.org/abs/2410.12934) was accepted by **ACL 2025**! We proposed an iterative verify-then-revise framework for LLMs on reasoning tasks.

- Feb 2025: A [first-authored paper](https://arxiv.org/abs/2502.08745) was accepted by **NAACL 2025**! We built IHEval, a novel benchmark for assessing LLMs' capability of following the instruction hierarchy.

- Feb 2025: A [co-authored paper](https://aclanthology.org/2025.naacl-long.137/) was accepted by **NAACL 2025**! We delivered a new evaluation benchmark for LLM-based recommender systems.

Contact
======
- Email: zhangzhihan719 [at] gmail.com
- Office: 611 Cowper Street, Palo Alto, CA
