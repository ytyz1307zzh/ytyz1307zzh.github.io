---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My name is Zhihan Zhang (张智涵). I am a fourth-year Ph.D. student in Computer Science and Engineering at the [University of Notre Dame](https://www.nd.edu/), advised by [Dr. Meng Jiang](http://www.meng-jiang.com/). I am currently a member of Dr. Jiang's [Data Mining towards Decision Making](http://www.meng-jiang.com/lab.html) (DM<sup>2</sup>) Lab. Prior to my Ph.D. career, I received my Bachelor's degree in Computer Science at [Peking University](https://www.pku.edu.cn/), where I had the fortune of working with [Dr. Yunfang Wu](https://cs.pku.edu.cn/info/1237/2096.htm) and [Dr. Xu Sun](https://xusun.org/). My research is mainly related to **instructing LLMs** to perform tasks for human users, such as instruction tuning, evaluation of instruction-following capabilities, etc.

For my past education and internship experience, please refer to [Experience](http://ytyz1307zzh.github.io/experience). For the full list of my publications, please refer to [Publications](http://ytyz1307zzh.github.io/publications) or check my [Google Scholar page](https://scholar.google.com/citations?user=7dcunDUAAAAJ&hl=en).

News
======
-  <img src="../images/new.png" width="25" align=center> Oct 2024: Several co-authored preprints came out! Check out our latest works:
    1. A state-of-the-art MLLM in the domain of text-rich images, trained on a multi-image text-rich corpus with 1M instruction data ([link](https://arxiv.org/abs/2410.01744))
    2. A new pipeline using process-supervised verifiers to make LLMs identify and revise their own reasoning errors ([link](https://arxiv.org/abs/2410.12934))
    3. A novel method to build autonomous LLM agents to solve software engineering tasks with a repository-level code graph ([link](https://arxiv.org/abs/2410.14684))
    4. A new benchmark that evaluates MLLMs' capabilities in multi-chart understanding and reasoning ([link](https://arxiv.org/abs/2410.14179))
      
-  <img src="../images/new.png" width="25" align=center> Sept 2024: 3 papers got accepted by **EMNLP 2024**! These include **two main conference papers**: a [first-authored paper](https://arxiv.org/abs/2406.12050) working on LMs & Math Reasoning and a [co-authored paper](https://arxiv.org/abs/2405.14092) working on LMs self-correcting their mistakes. And **one findings paper**: a [co-authored paper]() working on evaluating instruction-following capabilities of LMs.

-  Jun 2024: Several new preprints came out! Check out our latest works on math & multimodal reasoning: 
    * A [first-authored paper](https://arxiv.org/abs/2406.12050) incorporated reflection into LLM fine-tuning and improved their deep reasoning abilities.
    * A [co-authored paper](https://arxiv.org/abs/2405.14092) utilized backward verification methods to make LLMs identify and correct their own reasoning errors.
    * A [co-authored paper](https://arxiv.org/abs/2405.19444) released a benchmark on LLMs' math abilities in multi-turn interactions and open-ended generation.
    * A [co-authored paper](https://arxiv.org/abs/2404.14604) improved visual understanding capacity of MLLMs for more accurate multimodal math reasoning.
 
-  Jun 2024: I am joining Amazon as a full-time research intern in summer 2024.

-  May 2024: One [first-authored paper](https://arxiv.org/abs/2311.08711) is accepted to **ACL 2024** main conference! We studied the challenges in cross-lingual instruction-tuning and proposed a simple yet effective method to improve LLMs' proficiency in low-resource languages. Code is available on [Github](https://github.com/ytyz1307zzh/PLUG).

-  Feb 2024: I am joining Tecent America as a full-time research intern in spring 2024.

Contact
======
- Email: zzhang23 [at] nd.edu
- Office: 355 Fitzpatrick Hall of Engineering
- Location: University of Notre Dame, Notre Dame, IN 46556
